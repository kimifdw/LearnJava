# 并发
## 术语定义
1. 共享变量：在多个线程之间能够被共享的变量。他们被存放在堆内存中，Volatile只作用于共享变量。
   使用策略。
   1. 线程封闭。线程封闭的对象只能由一个线程拥有，对象呗封闭在该线程中，并且只能由这个线程修改；
   2. 只读共享。在没有额外同步的情况下，共享的只读对象可以由多个线程并发访问，但任务对象都不能修改它。共享的只读对象包括不可变对象和事实不可变对象；
   3. 线程安全共享。线程安全的对象在其内部实现同步，因此多个线程可以通过对象的公有接口来进行访问而不需要进一步的同步。
   4. 保护对象。被保护的对象只能通过持有特定的锁来访问。保护对象包括封装在其他线程安全对象中的对象，以及已发布的并且由某个特定锁保护的对象。

2. 正确的编写并发应用程序的方式。1.使代码正确运行，然后再提高代码的速度。即便如此，最好也只是当性能测试结果和应用需求告诉你必须提交性能，以及测量结果表明这种优化在实际环境中确实能带来性能提升时，才进行优化。

3. 线程安全。当多个线程访问某个类时，不管运行时环境采用何种调度方式或者这些线程将如何交替执行，并且在主调代码中不需要任何额外的同步或协同，这个类都能表现出正确的行为。无状态对象一定是线程安全的。

4. 内存屏障(Memory Barriers)：是一组处理器指令，用于实现对内存操作的顺序限制；

5. 缓冲行(Cache line)：缓存中可以分配的最小存储单位。

6. 原子操作（Atomic operation）: 即一个操作或多个操作要么全部执行并且执行的过程不会被任何因素打断，要不就都不执行；在多线程环境下，只保证**基本数据类型**的变量和**赋值操作**才是原子的；

7. 缓存行填充（cache line fill）：当处理器识别到从内存中读取操作数是可缓存的，处理器读取整个缓存行到适当的缓存；

8. 缓存命中（cache hit）：如果进行高速缓存行填充操作的内存位置仍然是下次处理器访问的地址时，处理器从缓存中读取操作数；

9. 写命中(write hit): 当处理器将操作数写回到一个内存缓存的区域时，它首先会检查这个缓存的内存地址是否在缓存行中，如果存在一个有效的缓存行，则将处理器这个操作数写回到内存；

10. 写缺失（write misses the cache)：一个有效的缓存行被写入到不存在的内存区域；

11. CAS(Compare and Swap): CAS操作需要输入两个值，一个旧值和一个新值，在操作期间先比较下旧值有没有发生变化，如果没有发生变化，才交换成新值，发生了变化则不交换。

12. 哈希算法：是一种将任意内容的输入转换成相同长度输出的加密方式；

13. 哈希表：根据设定的哈希函数和处理冲突方法，将一组关键字映射到一个有限的地址区间上，并以关键字所在地址区间中的象作为记录在表中的存储位置；

14. Ncpu：cpu的数量【Runtime.getRuntime().availableProcessors()】

15. Ucpu：cpu当前的利用率

16. W/C: 等待时间和计算时间的占比

17. Nthreads=Ncpu*Ucpu*(1+W/C)

18. CPU流水线(CPU pipeline)：CPU流水线的工作方式就象工业生产上的装配流水线，在CPU中由5~6个不同功能的电路单元组成一条指令处理流水线，然后将一条X86指令分成5~6步后再由这些电路单元分别执行，这样就能实现在一个CPU时钟周期完成一条指令，因此提高CPU的运算速度。

19. 内存顺序冲突：内存顺序冲突一般是由假共享引起，假共享是指多个CPU同时修改同一个缓存行的不同部分而引起其中一个CPU的操作无效，当出现这个内存顺序冲突时，CPU必须清空流水线。

20. 总线锁：使用处理器提供的一个LOCK#信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住,那么该处理器可以独占使用共享内存。

21. 缓存锁：如果缓存在处理器缓存行中内存区域在LOCK操作期间被锁定，当它执行锁操作回写内存时，处理器不在总线上声言LOCK # 信号，而是修改内部的内存地址，并允许缓存一致性机制来保证操作的原子性。

22. 公平访问队列：阻塞的所有生产者线程或消费者线程，当队列可用时，可以按照阻塞的先后顺序访问队列，即先阻塞的生产者线程，可以先往队列里插入元素，先阻塞的消费者线程，可以先从队列里获取元素。

23. 工作窃取算法：指某个线程从其他队列里窃取任务来执行。优点是充分利用线程进行并行计算，并减少了线程间的竞争，缺点还是存在竞争

24. 生产者消费者模式：通过一个容器来解决生产者和消费者的强耦合问题。用来解决的是消费者和生产者速率不一致而产生的阻抗不匹配。

25. 回调地狱（callback hell）现象。在追踪代码在回调过程中到底做了什么，以及确保每个回调只访问它需要的数据的时候，变得非常困难。

26. 竞态条件：当两个线程竞争**同一资源**时，并且其中的一个或者多个线程对这个资源进行了写操作，就称为存在竞态条件。多个线程同时读同一个资源**不会**产生竞态条件。

27. 线程同步的机制。
    1. 临界区。
        1. 定义。
            1. 通过对多线程的串行化来访问公共资源或一段代码，速度快，适合控制数据访问。在任意时刻只允许一个线程对共享资源进行访问，如果有多个线程试图访问公共资源，那么在有一个线程进入后，其他试图访问公共资源的线程将被挂起，并一直等到进入临界区的线程离开，临界区在被释放后，其他线程才可以抢占。
            2. 一个访问**共用资源**的程序片段，而这些共用资源**又无法**同时被多个线程访问。
        2. 规定。
            1. **每次只准许一个进程进入临界区，进入后不允许其他进程进入。**
            2. 如果有若干进程要求进入空闲的临界区，一次仅允许一个进程进入。
            3. 任何时候，处于临界区内的进程不可多一个。
            4. 进入临界区的进程要在有限时间内退出，以便其它进程能及时进入自己的临界区。
            5. 如果进程不能进入自己的临界区，则应让出CPU，避免进程出现“忙等”现象。
    2. 互斥量。采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限，因为互斥对象只有一个，所以能保证公共资源不会同时被多个线程访问。互斥不仅能实现同一应用程序的公共资源安全共享，还能实现不同应用程序的公共资源安全共享。
    3. 信号量。允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。
    4. 事件。通过通知操作的方式来保持线程的同步，还可以方便实现对多个线程的优先级比较操作。

28. 互斥：这个资源只有我用，你不许用；原子：我一口气把活干完，不间断。

29. 线程安全的代码：允许被多个线程同时执行的代码

30. 局部变量：存储在线程自己的栈中，永远不会被多个线程共享，所以基础类型的局部变量是线程安全的。

31. 线程控制逃逸规则。如果一个资源的创建、使用、销毁都在同一个线程内完成，且永远不会脱离该线程的控制，则该资源的使用就是线程安全的。

32. 监视器对象：在同步构造器中用括号括起来的对象，一次只有一个线程能够在同步于同一个监视器对象的java方法内执行。

33. 加锁约定。将所有的可变状态都封装在对象内部，并通过对象的内置锁对所有访问可变状态的代码路径进行同步，使得在该对象上不会发生并发访问。

34. 正确的发布对象。
    1. 在静态初始化函数中初始化一个对象引用
    2. 将对象的引用保存到volatile类型的域或者AtomicReferance对象中；
    3. 将对象的引用保存到某个正确构造对象的final类型域中；
    4. 将对象的引用保存到一个由锁保护的域中；

35. 线程封闭。仅在单线程内访问数据，不需要同步。Ad-hoc线程封闭。维护线程封闭性的职责完全由程序实现来承担。

36. 事实不可变对象。对象从技术上来看是可变的，但其状态在发布后不会再次改变。

37. 线程方法。
    1. yield。
        1. 调用yield()方法的线程告诉虚拟机它乐意让其他线程占用自己的位置。但这是个**暗示**，并不能保证会产生任何影响。
        2. yield是一个静态的原生方法。
        3. 告诉当前正在执行的线程把运行机会交给线程池中拥有*相同优先级*的线程。
        4. 不能保证一个正在运行的线程迅速转换到可运行的状态。
        5. 仅能使一个线程从运行状态转到可运行状态，而不是等待或阻塞状态。
        6. **不能**保证线程能够交替执行
    2. join。一个线程在另一个线程结束后再执行。如果join()方法在一个线程实例上调用，当前运行着的线程将阻塞直到这个线程实例完成执行。
    3. start。调用run()方法来执行线程，结果会**立刻**返回，新线程是异步运行的。
    4. interrupt。终止线程。只会对waiting或timed_waiting方法起作用。
    5. interrupted。检查**当前线程**是否已经interrupted。
    6. isInterrupted。检查**任意线程**是否已经interrrupted。
    7. notify。将wait的线程唤醒

38. 线程状态。
    1. new。线程未运行。
    2. Runnable（处于可运行状态或正在运行状态）。使用yield可使线程状态有Running变为can running。
    3. Blocked。等待获取锁时进入的状态。
    4. Waiting。当正处于Running的线程等待变成激活状态的通知。
    5. Timed Waiting。
    6. Terminated.

39. 线程优先级
    1. 线程的优先级没有指定时，所有线程携带普通优先级；
    2. 优先级可以用1到10的范围指定。10表示最高优先级，1表示最低优先级，5表示普通优先级；
    3. 优先级最高的线程在执行时被给予优先执行，但**不能保证**线程在启动时进入运行状态；
    4. 在与线程池中等待运行机会的线程相比，当前运行的线程可能总是拥有更高的优先级；
    5. 由调度程序决定哪个线程被执行；
    6. 在线程方法被调用之前，线程的优先级应该被设定；

40. 设计线程安全的类。
    1. 找出构成对象状态的所有变量；
    2. 找出约束状态变量的不变性条件；
    3. 建立对象状态的并发访问管理策略； 

## 并发模型
1. 并行工作者。委派者(Delegator)将传入的作业分配给不同的工作者，每个工作者完成整个任务。适用于并行、独立的并且没有必要共享状态
   1. 优点。容易理解
   2. 缺点。共享状态可能会很复杂；无状态的工作者(每次都要重读需要的数据)；任务顺序是不确定的
2. 流水线模式。使用非阻塞的IO来设计使用流水线并发模型
   1.  Actors。每个工作者被称为actor,可以直接异步地发送和处理消息
   2.  Channels。工作者之间不直接通信，而是在不同的通道中发布自己的消息
   3.  优点。
       1. 无需共享的状态；
       2. 有状态的工作者；
       3. 较好的硬件整合；
       4. 合理的作业顺序；
   4.  缺点。作业的执行往往分布到多个工作者上。
3. 函数式并行。采用函数调用实现程序，java7中的`ForkAndJoinPool`和java8中的`stream`来并行的实现迭代大型集合。
## volatile（稍弱的同步机制）
1. 定义：java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致的更新，线程应该确保通过排他锁单独获得这个变量。当一个变量被声明为volatile类型后，编译器与运行时都会注意到这个变量是共享的，因此不会将该变量重排序，也不会被缓存在寄存器或者对其他处理器不可见的地方，所以总会返回最新写入的值。
2. 用于修饰在多线程环境下某一变量值的一致性；
3. 在LinkedTransferQueue中，使用了volatile，追加64字节提高并发编程性能；
4. 可见性：一个线程修改了这个变量的值，会立马写回主存储器中，这样就能被另一个线程看到这个变量的值得变化（**多线程是并发不是并行**）。确保编译器不会对代码作寄存器优化。从内存可见性的角度，写入volatile变量相当于退出同步代码块，而读取volatile变量相当于进入同步代码块。
5. 正确的使用方式。
   1. 确保它们自身状态的可见性；
   2. 确保它们所引用对象的状态的可见性；
   3. 标识一些重要的程序生命周期事件的发生；
   4. 对变量的写入操作不依赖变量的当前值，或者能确保只有单个线程更新变量的值
   5. 该变量不会与其他状态变量一起纳入不变性条件中
   6. 在访问变量时不需要加锁。
   7. 仅当volatile能简化代码实现以及对同步策略的验证时，才应该使用它们；
6. 仅当一个变量参与到包含其他状态变量的不变性条件时，才可以声明为volatile类型。
7. volatile无法保证复合操作的原子性。
## synchronized
- 锁一旦升级为重量级锁，就不会再降级；JVM会尽量维持在低能耗锁
- 所有同步在一个对象上的同步块在同时只能被一个线程进入并执行操作
- 在很大的方法中声明synchronized，将大大影响效率。如果一定要使用synchronized关键字，可以用synchronized代码块代替synchronized方法。
- 以代码块来实现synchronized，常用`synchronized(this)`的方式
1. 同步的基础
    1. 对于同步方法，锁是当前**实例对象**
    2. 对于静态同步方法，锁是当前对象的**class对象**
    3. 对于同步方法块，锁是Synchonized*括号*里配置的对象
    4. 同步方法的实质是将synchronized作用于**Object reference**。
2. 锁的四种状态
    1. 无状态锁；
    2. 偏向锁状态；
    3. 轻量级锁状态；
    4. 重量级锁状态；
3. 偏向锁
    1. 要解决的问题：大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得。
    2. 锁的获得：测试对象头的Mark Word里是否存在存储着指向当前线程的偏向锁，如不存在，则再测试下Mark Word中偏向锁的标识是否为1，没有设置则使用CAS竞争锁；
    3. 锁的撤销：需要等待全局安全点，它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，必须等到同步代码块执行完；
    4. 关闭偏向锁：在java6和java7中默认启用，通过jvm参数关闭偏向锁：**UseBiasedLocking=false**，那么默认会进入**轻量级锁**状态；
    5. 适用于**只有一个线程**访问同步块；
    6. 偏向锁的耗能比轻量级锁少
4. 轻量级锁
    1. 加锁：线程在执行同步块前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中。
    2. 解锁：使用原子的CAS操作来讲Displaced Mark Word替换回到对象头；
    3. 如果始终得不到锁竞争的线程使用自旋会消耗CPU;
    4. 适用场景：追求响应时间；同步块执行速度非常快；
5. 重量级锁
    1. 线程竞争不使用自旋，不会消耗CPU；
    2. 适用场景：追求吞吐量；同步块执行时间较长
6. 同步机制。通过给对象加锁实现的，为了防止同时访问共享资源。对于静态方法的同步会同步在类对象上，而实例方法是属于实例对象
7. 同步目的。保证写资源的唯一性。
8. synchronized(this)
    1. 当两个并发线程访问同一个对象object中的这个synchronized(this)同步代码块时，一个时间内只能有一个线程得到执行。另一个线程必须等待当前线程执行完这个代码块以后才能执行该代码块。
    2. 当一个线程访问object的一个synchronized(this)同步代码块时，另一个线程仍然可以访问object中的非synchronized(this)同步代码块。
    3. 当一个线程访问object的一个synchronized(this)同步代码块时，其他线程对object中所有**其他synchronized(this)同步代码块**得访问将被阻塞。
    4. 当一个线程访问object的一个synchronized(this)同步代码块时，它就获得了这个object的对象锁。结果，其他线程对该object对象所有同步代码部分的访问都将被暂时阻塞。
9. 注意点。
    1. 无论synchronized加在方法上还是对象上，它取得的锁是**对象**，这里的对象是**调用这个同步方法**的对象。
    2. 每个对象**只有一个锁**与之相关联。
    3. 要尽量避免无谓的同步。
    4. 没有明确的对象作为锁，可以创建一个特殊的instance对象。`private byte[] lock = new byte[0]；`
    5. 定义private的instance变量+它的get方法，而**不要**定义public/protected的instance变量。如果将变量定义为public，对象在外界可以绕过同步方法的控制而直接取得它，并改动它.
    6. 如果instance变量是一个对象，如数组或ArrayList什么的，那上述方法仍然不安全，因为当外界对象通过get方法拿到这个instance对象的引用后，又将其指向另一个对象，那么这个private变量也就变了，岂不是很危险。 这个时候就需要将get方法也加上synchronized同步，并且，只返回这个private对象的clone()――这样，调用端得到的就是对象副本的引用了
    7. `synchronized(Foo.class)`等同于`public synchronized static void methodAAA()`，取得的锁是当前调用这个方法的对象所属的类，而不是这个类产生的**某个具体对象**。
    8. 对于同步的方法或代码块来说，必须获得对象锁才能够进入同步方法或代码块进行操作；
    9. 如果采用method级的同步，则对象锁即为method所在的*对象*；如果是**静态方法**，对象锁即为method所在的*Class对象(唯一)*
    10. 静态方法一定会同步，非静态方法需在**单例模式**下生效。

## JAVA线程池的分析和使用
1.  好处：
    1. 降低资源消耗。
    2. 提高响应速度。
    3. 提高线程的可管理性。
2.  使用
                      `new ThreadPoolExecutor(corePoolSize,maximumPoolSize,keepAliveTime,milliseconds,runnableTaskQueue,handler)`
    1. corePoolSize(线程池的基本大小)：当提交一个任务到线程池时，线程池会创建一个线程来执行任务，即使其他空闲的基本线程能够执行新任务也会创建线程，等到需要执行的任务数大于线程池基本大小时不再创建。如果调用了线程池的**prestartAllCoreThreads**方法，线程池会提前创建并启动所有基本线程。
    2. runnableTaskQueue(任务队列)：用于保存等待执行的任务的阻塞队列，队列里处处的是以前提交的任务，需要等待线程空闲时执行。
        * ArrayBlockingQueue：基于数组结构的有界阻塞队列，FIFO（先进先出）
        * LinkedBlockingQueue：基于链表结构的阻塞队列，FIFI（先进先出），Executors.newFixedThreadPool()【设置corePoolSize==maximumPoolSize】使用这个队列
        * SynchronousQueue: 不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作，Executors.newCachedThreadPool()使用这个队列
        * PriorityBlockingQueue: 一个具有优先级的无限阻塞队列。
    3. maximumPoolSize(线程池的最大值)   
    4. ThreadFactory：设置创建线程的工厂
    5. RejectedExecutionHandler(饱和策略)：当线程池处于饱和状态时采取的处理新提交的新任务的策略。默认AbortPolicy
        * AbortPolicy: 直接抛出异常；
        * CallerRunsPolicy: 只能调用者所在线程来运行任务；
        * DiscardOldestPolicy: 丢弃队列里最近的一个任务，并执行当前任务；
        * DiscardPolicy: 不处理，丢弃掉
    6. keepAliveTime（线程活动保持时间）：工作线程空闲后，保持存活的时间。
    7. TimeUnit(线程活动保持的单位)
3.  提交任务
    1. execute(): 没有返回值
    2. submit(): 返回Future返回值。*InterruptedException*(处理中断异常)；*ExecutionException*(处理无法执行任务异常)
4.  线程池关闭
    1. 原理：遍历线程池中的工作线程，逐个调用线程的interrupt方法来中断线程
    2. isShutdown(): 调用shutdown和shutdownnow都会变为true；
    3. isTerminaed()：所有任务已关闭后，才表示线程池关闭成功。
5.  线程池流程
    1. 判断基本线程池是否已满；
    2. 判断工作队列是否已满；
    3. 判断整个线程池是否已满；
6.  合理的配置线程池
    1. 分析任务特性
        1. 任务性质：CPU密集型任务，IO密集型任务和混合型任务。
            1. CPU密集型：尽可能小的线程（Ncpu+1），例如压缩和解压缩
            2. IO密集型：尽可能多的线程(2*Ncpu)
            3. `Runtime.getRuntime().availableProcessors()`：当前设备的CPU个数
        2. 任务优先级：高、中、低。使用*PriorityBlockingQueue*队列
        3. 任务的执行时间：长、中、短。使用不同规模的线程池来处理
        4. 任务的依赖性：是否依赖其他系统资源。设置线程数尽可能大。
    2. 建议使用*有界对列*
    3. 动态递增的增加线程池数目
7.  线程池的监控
    1. taskCount: 线程池需要执行的任务数量
    2. completedTaskCount: 线程池在运行过程中已完成的任务数量。
    3. largestTaskCount：曾经创建过的最大线程数量
    4. getPoolSize: 线程池的线程数量
    5. getActiveCount: 获取活动的线程数
    6. 重写线程池的beforeExecute、afterExecute和terminated方法。ø
8.  应急处理：如果在创建线程池的时候，指定的*corePoolSize<maximumPoolsize*是会出现你说的这种情况
## 自旋CAS问题
1. ABA问题：如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值并没有变。*解决思路*：使用版本号。`AtomicStampedReference`来解决ABA问题
2. 循环时间长开销大
3. 只能保证一个共享变量的原子操作。
4. 使用*锁*机制实现原子操作
5. 自旋的核心。由硬件支持的一个cpu不断check高速缓存的操作，为了减少线程切换到内核态。
## 阻塞队列
1. 定义：一个支持两个附加操作的队列。（在队列为空时，获取元素的线程会等待队列变为非空；当队列满时，存储元素的线程会等待队列可用。）
2. 处理方法
   1. 抛出异常：当阻塞队列满时，往队列里插入元素会抛出异常；当队列为空时，从队列里获取元素时会抛出异常；
   2. 返回特殊值：插入方法会返回是否成功，成功返回TRUE；如果队列里拿出一个元素如果没有则返回null
   3. 一直阻塞：当阻塞队列满时，会阻塞往队列里put的生产者线程；当队列为空，会阻塞消费者线程，直到队列可用
   4. 超时退出：当阻塞队列满时，队列会阻塞生产者线程一段时间，如果超过一定的时间，生产者线程就会退出。
3. 7个阻塞队列
   1. ArrayBlockingQueue：一个由数组结构组成的有界阻塞队列，按照先进先出原则对元素进行排序
   2. LinkedBlockingQueue：一个由链表结构组成的有界阻塞队列，按照先进先出的原则，最大长度为`Integer.MAX_VALUE`
   3. PriorityBlockingQueue ：一个支持优先级排序的无界阻塞队列。
   4. DelayQueue：一个使用优先级队列实现的无界阻塞队列，必须实现Delayed接口，可以用于缓存系统、定时任务调度
   5. SynchronousQueue：一个不存储元素的阻塞队列，适用于将一个线程使用的数据传递给另一个线程使用
   6. LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。
   7. LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列
4. 实现原理
   1. 使用通知模式实现，当生产者往满的队列里添加元素时会阻塞住生产者，当小费者消费了一个队列中的元素后，会通知生产者当前队列可用。
   2. 利用重入锁(`ReentrantLock`)控制
## Fork/Join框架
1. 定义：用于并行执行任务的框架，是把一个大任务分割成若干个小人物，最终汇总每个小任务结果后得到大任务结果的框架
2. 两个类
   1. ForkJoinTask。(`RecursiveAction`：用于没有返回结果的任务；`RecursiveTask`：用于有返回的任务）
   2. ForkJoinPool
3. 实现原理
   1. ForkJoinPool由`ForkJoinTask`数组[负责存放程序提交给ForkJoinPool的任务]和`ForkJoinWorkerThread`数组[负责执行这些人]组成
   2. ForkJoinTask的fork原理。调用`ForkJoinWorkerThread`的`pushTask`方法，将任务存放在ForkJoinWorkerThread队列里，调用`signalWork()`异步的执行这个任务，然后立即返回结果。
   3. ForkJoinTask的join方法。阻塞当前线程并等待获取结果，四种任务状态【已完成(NORMAL)、被取消(CANCELLED)、信号(SIGNAL)和异常(EXCEPTIONAL)】
## 线程安全与共享资源
1. 局部变量中的基本数据类型(8种)永远是线程安全的
2. 局部变量中的对象类型只要不会被其他线程访问到，也是线程安全的；
3. 一个对象实例被多个线程同时访问时，他的成员变量就可能是线程不安全的；
## java内存模型[未完成]
1. 原理：划分为线程栈和堆。
   1. 线程堆。每个运行在java虚拟机里的线程都拥有自己的线程栈。包含了这个线程调用的方法当前执行点相关的信息。一个线程仅能访问自己的线程栈，一个线程创建的本地变量对其他线程不可见。每个线程拥有每个本地变量的独有版本。
   2. 堆。包含java程序创建的所有对象。不管一个对象被创建然后赋值给一个局部变量或者用来作为另一个对象的成员变量，这个对象仍然存放在堆上。
## 线程通信
1. 通过共享对象通信。
2. 忙等待。
3. wait()、notify()和notifyAll()。线程必须在同步块里调用`wait()`或`notify()`，不要使用全局对象，字符串常量等。应使用唯一的对象。
4. 丢失的信号。(**MyWaitNotify2.java**)
5. 假唤醒。线程在没有调用过`notify()`和`notifyAll()`的情况下醒来。(**MyWaitNotify3.java**)
6. 多个线程等待相同信号。(**MyWaitNotify3.java**)
7. 不要在字符串常量[**值为常量的变量**]或全局对象中调用wait()
## ThreadLocal（线程局部变量）
1. 定义。创建的变量只被同一个线程进行读和写操作。`private ThreadLocal myThreadLocal  = new ThreadLocal();`，每个线程只能看到私有的ThreadLocal实例，所以不同的线程在给ThreadLocal对象设置不同的值时，他们也不能看到彼此的修改。防止对可变的单实例变量或全局变量进行共享。
2. 访问。`myThreadLocal.set("A thread local value");`或`String threadLocalValue = (String) myThreadLocal.get();`当某个频繁执行的操作需要一个临时对象，而同时又希望避免在每次执行时都重新分配该临时对象，就可以使用ThreadLocal。
3. ThreadLocal泛型。`private ThreadLocal myThreadLocal1 = new ThreadLocal<String>();`。
4. 初始化ThreadLocal。重写initialValue方法可以让所有线程都可以看到初始化值。
5. InheritableThreadLocal。为了解决ThreadLocal实例内部每个线程都只能看到自己的私有值，允许一个线程创建的所有子线程访问其父线程。
## 死锁
1. 定义。两个或更多线程阻塞着等待其它处于死锁状态的线程所持有的锁。
2. 如何发现死锁。
   1. 阅读code。检查嵌套的synchronized同步块代码或者调用synchronized方法。
   2. 利用操作系统的命令。`kill -3`。能够打印当前应用里所有线程的状态。
   3. 使用`jconsole`。
3. 解决方案。
   1. 加锁顺序。
   2. 加锁时限。在尝试获取锁的时候加一个超时时间，若一个线程没有在给定的时限内成功获得所有需要的锁，则会进行回退并释放所有已经获得的锁，然后等待一段随机的时间再重试。不能对`synchronized`同步块设置超时时间
   3. 死锁检测。
      1. 针对那些不可能实现按序加锁并且锁超时也不可行的场景。
      2. 解决方案。
         1. 释放所有锁，回退，并且等待一段随机的时间后重试。
         2. 给线程设置随机优先级。
## 容器同步类
1. 组成。Vector，Hashtable，还包括Collections.synchronizedXxx等工厂方法。
2. 问题。
    1. Vector上可能导致混乱结果的复合操作。
    2. 迭代器和ConcurrentModificationException。
    3. 隐藏迭代器。
3. 封装对象的状态有助于维持不变性条件一样，封装对象的同步机制同样有助于确保实施同步策略。
## 并发容器
1. ConcurrentHashMap。
    1. 在并发情况下不要使用HashMap，导致CPU利用率100%；
    2. HashTable容器使用synchronized来保证线程安全，但效率低下，原因是所有访问HashTable线程都必须竞争同一把锁
    3. 由*Segment*数组结构和*HashEntry*数组结构组成。Segment是一把**ReentrantLock锁**
    4. get方法，用volatile替换锁，所以读取效率比HashTable高；put方法需要用到锁。
    5. 原理。使用分段锁的加锁机制来实现更大程度的共享，任意数量的读取线程可以并发地访问Map，执行读取操作的线程和执行写入操作的线程可以并发访问Map
2. CopyOnWriteArrayList（高效读取）。在遍历操作为操作的情况下代替同步的List。
    1. 原理。正确地发布一个事实不变的对象，在访问该对象时就不再需要进一步的同步。
    2. 适用场景。迭代远远大于修改操作。
    3. 读取是完全不用加锁的，写入也不会阻塞读取操作。
3. Queue。
    1. ConcurrentLinkedQueue。先进先出队列
        1. 基于链接节点的无界线程安全队列，采用先进先出的规则对节点进行排序
        2. 采用"wait-free"算法实现,默认情况下head节点存储的元素为空，tair节点等于head节点
        3. 入队列：将入队节点添加到队列的尾部
    2. PriorityQueue。非并发的优先队列。
    3. BlockingQueue。增加了可阻塞的插入和获取等操作。
4. 阻塞方法与中断方法。处理中断响应。1. 传递InterruptedException。2. 恢复中断。
## 同步工具类
1. 阻塞队列。
2. 闭锁。
    1. 确保某些活动直到其他活动都完成后才继续执行。
    2. CountDownLatch。
        1. 工作原理。包含一个计数器，初始化为一个正数，表示需要等待的事件数量；countDown方法递减计数器，表示一个事件已经发生了；await方法表示所有需要等待的事件都已经发生。
    3. FutureTask。
3. 信号量。
    1. 定义。一个线程同步结构，用于在线程间传递信号，以避免出现信号丢失或像锁一样用于保护一个关键区域。
    2. 允许指定多个线程同时访问某一个资源。
4. 栅栏。
    1. 定义。能阻塞一组线程直到某个事件发生。
    2. 与闭锁的区别。所有线程必须同时到达栅栏位置，才能继续执行。
    3. CyclicBarrierDemo[循环栅栏]
