# 并发
## 术语定义
1. 共享变量：在多个线程之间能够被共享的变量。他们被存放在堆内存中，Volatile只作用于共享变量。
   使用策略。
   1. 线程封闭。线程封闭的对象只能由一个线程拥有，对象呗封闭在该线程中，并且只能由这个线程修改；
   2. 只读共享。在没有额外同步的情况下，共享的只读对象可以由多个线程并发访问，但任务对象都不能修改它。共享的只读对象包括不可变对象和事实不可变对象；
   3. 线程安全共享。线程安全的对象在其内部实现同步，因此多个线程可以通过对象的公有接口来进行访问而不需要进一步的同步。
   4. 保护对象。被保护的对象只能通过持有特定的锁来访问。保护对象包括封装在其他线程安全对象中的对象，以及已发布的并且由某个特定锁保护的对象。

2. 正确的编写并发应用程序的方式。1.使代码正确运行，然后再提高代码的速度。即便如此，最好也只是当性能测试结果和应用需求告诉你必须提交性能，以及测量结果表明这种优化在实际环境中确实能带来性能提升时，才进行优化。

3. 线程安全。当多个线程访问某个类时，不管运行时环境采用何种调度方式或者这些线程将如何交替执行，并且在主调代码中不需要任何额外的同步或协同，这个类都能表现出正确的行为。无状态对象一定是线程安全的。

4. 内存屏障(Memory Barriers)：是一组处理器指令，用于实现对内存操作的顺序限制；

5. 缓冲行(Cache line)：缓存中可以分配的最小存储单位。

6. 原子操作（Atomic operation）: 不可中断的一个或一系列操作；

7. 缓存行填充（cache line fill）：当处理器识别到从内存中读取操作数是可缓存的，处理器读取整个缓存行到适当的缓存；

8. 缓存命中（cache hit）：如果进行高速缓存行填充操作的内存位置仍然是下次处理器访问的地址时，处理器从缓存中读取操作数；

9. 写命中(write hit): 当处理器将操作数写回到一个内存缓存的区域时，它首先会检查这个缓存的内存地址是否在缓存行中，如果存在一个有效的缓存行，则将处理器这个操作数写回到内存；

10. 写缺失（write misses the cache)：一个有效的缓存行被写入到不存在的内存区域；

11. CAS(Compare and Swap): CAS操作需要输入两个值，一个旧值和一个新值，在操作期间先比较下旧值有没有发生变化，如果没有发生变化，才交换成新值，发生了变化则不交换。

12. 哈希算法：是一种将任意内容的输入转换成相同长度输出的加密方式；

13. 哈希表：根据设定的哈希函数和处理冲突方法，将一组关键字映射到一个有限的地址区间上，并以关键字所在地址区间中的象作为记录在表中的存储位置；

14. Ncpu：cpu的数量【Runtime.getRuntime().availableProcessors()】

15. Ucpu：cpu当前的利用率

16. W/C: 等待时间和计算时间的占比

17. Nthreads=Ncpu*Ucpu*(1+W/C)

18. CPU流水线(CPU pipeline)：CPU流水线的工作方式就象工业生产上的装配流水线，在CPU中由5~6个不同功能的电路单元组成一条指令处理流水线，然后将一条X86指令分成5~6步后再由这些电路单元分别执行，这样就能实现在一个CPU时钟周期完成一条指令，因此提高CPU的运算速度。

19. 内存顺序冲突：内存顺序冲突一般是由假共享引起，假共享是指多个CPU同时修改同一个缓存行的不同部分而引起其中一个CPU的操作无效，当出现这个内存顺序冲突时，CPU必须清空流水线。

20. 总线锁：使用处理器提供的一个LOCK#信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住,那么该处理器可以独占使用共享内存。

21. 缓存锁：如果缓存在处理器缓存行中内存区域在LOCK操作期间被锁定，当它执行锁操作回写内存时，处理器不在总线上声言LOCK # 信号，而是修改内部的内存地址，并允许缓存一致性机制来保证操作的原子性。

22. 公平访问队列：阻塞的所有生产者线程或消费者线程，当队列可用时，可以按照阻塞的先后顺序访问队列，即先阻塞的生产者线程，可以先往队列里插入元素，先阻塞的消费者线程，可以先从队列里获取元素。

23. 工作窃取算法：指某个线程从其他队列里窃取任务来执行。优点是充分利用线程进行并行计算，并减少了线程间的竞争，缺点还是存在竞争

24. 生产者消费者模式：通过一个容器来解决生产者和消费者的强耦合问题。用来解决的是消费者和生产者速率不一致而产生的阻抗不匹配。

25. 回调地狱（callback hell）现象。在追踪代码在回调过程中到底做了什么，以及确保每个回调只访问它需要的数据的时候，变得非常困难。

26. 竞态条件：当两个线程竞争**同一资源**时，并且其中的一个或者多个线程对这个资源进行了写操作，就称为存在竞态条件。多个线程同时读同一个资源**不会**产生竞态条件。

27. 临界区：导致竞态条件发生的代码区。

28. 互斥：这个资源只有我用，你不许用；原子：我一口气把活干完，不间断。

29. 线程安全的代码：允许被多个线程同时执行的代码

30. 局部变量：存储在线程自己的栈中，永远不会被多个线程共享，所以基础类型的局部变量是线程安全的。

31. 线程控制逃逸规则。如果一个资源的创建、使用、销毁都在同一个线程内完成，且永远不会脱离该线程的控制，则该资源的使用就是线程安全的。

32. 监视器对象：在同步构造器中用括号括起来的对象，一次只有一个线程能够在同步于同一个监视器对象的java方法内执行。

33. 加锁约定。将所有的可变状态都封装在对象内部，并通过对象的内置锁对所有访问可变状态的代码路径进行同步，使得在该对象上不会发生并发访问。

34. 正确的发布对象。

   1. 在静态初始化函数中初始化一个对象引用
   2. 将对象的引用保存到volatile类型的域或者AtomicReferance对象中；
   3. 将对象的引用保存到某个正确构造对象的final类型域中；
   4. 将对象的引用保存到一个由锁保护的域中；

35. 线程封闭。仅在单线程内访问数据，不需要同步。Ad-hoc线程封闭。维护线程封闭性的职责完全由程序实现来承担。

36. 事实不可变对象。对象从技术上来看是可变的，但其状态在发布后不会再次改变。
## 并发模型
1. 并行工作者。委派者(Delegator)将传入的作业分配给不同的工作者，每个工作者完成整个任务。适用于并行、独立的并且没有必要共享状态
   1. 优点。容易理解
   2. 缺点。共享状态可能会很复杂；无状态的工作者(每次都要重读需要的数据)；任务顺序是不确定的
2. 流水线模式。使用非阻塞的IO来设计使用流水线并发模型
   1.  Actors。每个工作者被称为actor,可以直接异步地发送和处理消息
   2.  Channels。工作者之间不直接通信，而是在不同的通道中发布自己的消息
   3.  优点。
       1. 无需共享的状态；
       2. 有状态的工作者；
       3. 较好的硬件整合；
       4. 合理的作业顺序；
   4.  缺点。作业的执行往往分布到多个工作者上。
3. 函数式并行。采用函数调用实现程序，java7中的`ForkAndJoinPool`和java8中的`stream`来并行的实现迭代大型集合。
## volatile（稍弱的同步机制）
1. 定义：java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致的更新，线程应该确保通过排他锁单独获得这个变量。当一个变量被声明为volatile类型后，编译器与运行时都会注意到这个变量是共享的，因此不会将该变量重排序，也不会被缓存在寄存器或者对其他处理器不可见的地方，所以总会返回最新写入的值。
2. 用于修饰在多线程环境下某一变量值的一致性；
3. 在LinkedTransferQueue中，使用了volatile，追加64字节提高并发编程性能；
4. 可见性：一个线程修改了这个变量的值，会立马写回主存储器中，这样就能被另一个线程看到这个变量的值得变化（**多线程是并发不是并行**）。确保编译器不会对代码作寄存器优化。从内存可见性的角度，写入volatile变量相当于退出同步代码块，而读取volatile变量相当于进入同步代码块。
5. 正确的使用方式。
   1. 确保它们自身状态的可见性；
   2. 确保它们所引用对象的状态的可见性；
   3. 标识一些重要的程序生命周期事件的发生；
   4. 对变量的写入操作不依赖变量的当前值，或者能确保只有单个线程更新变量的值
   5. 该变量不会与其他状态变量一起纳入不变性条件中
   6. 在访问变量时不需要加锁。
## synchronized
- 锁一旦升级为重量级锁，就不会再降级；JVM会尽量维持在低能耗锁
- 所有同步在一个对象上的同步块在同时只能被一个线程进入并执行操作
1. 同步的基础
    1. 对于同步方法，锁是当前**实例对象**
    2. 对于静态同步方法，锁是当前对象的**class对象**
    3. 对于同步方法块，锁是Synchonized括号里配置的对象
2. 锁的四种状态
    1. 无状态锁；
    2. 偏向锁状态；
    3. 轻量级锁状态；
    4. 重量级锁状态；
3. 偏向锁
    1. 要解决的问题：大多数情况下锁不仅不存在多线程竞争，而且总是由同一线程多次获得。
    2. 锁的获得：测试对象头的Mark Word里是否存在存储着指向当前线程的偏向锁，如不存在，则再测试下Mark Word中偏向锁的标识是否为1，没有设置则使用CAS竞争锁；
    3. 锁的撤销：需要等待全局安全点，它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，必须等到同步代码块执行完；
    4. 关闭偏向锁：在java6和java7中默认启用，通过jvm参数关闭偏向锁：**UseBiasedLocking=false**，那么默认会进入**轻量级锁**状态；
    5. 适用于**只有一个线程**访问同步块；
    6. 偏向锁的耗能比轻量级锁少
4. 轻量级锁
    1. 加锁：线程在执行同步块前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中。
    2. 解锁：使用原子的CAS操作来讲Displaced Mark Word替换回到对象头；
    3. 如果始终得不到锁竞争的线程使用自旋会消耗CPU;
    4. 适用场景：追求响应时间；同步块执行速度非常快；
5. 重量级锁
    1. 线程竞争不使用自旋，不会消耗CPU；
    2. 适用场景：追求吞吐量；同步块执行时间较长
6. 同步机制。通过给对象加锁实现的，为了防止同时访问共享资源。对于静态方法的同步会同步在类对象上，而实例方法是属于实例对象
7. 同步目的。保证写资源的唯一性。

## JAVA线程池的分析和使用
1.  好处：
    1. 降低资源消耗。
    2. 提高响应速度。
    3. 提高线程的可管理性。
2.  使用
                      `new ThreadPoolExecutor(corePoolSize,maximumPoolSize,keepAliveTime,milliseconds,runnableTaskQueue,handler)`
    1. corePoolSize(线程池的基本大小)：当提交一个任务到线程池时，线程池会创建一个线程来执行任务，即使其他空闲的基本线程能够执行新任务也会创建线程，等到需要执行的任务数大于线程池基本大小时不再创建。如果调用了线程池的**prestartAllCoreThreads**方法，线程池会提前创建并启动所有基本线程。
    2. runnableTaskQueue(任务队列)：用于保存等待执行的任务的阻塞队列，队列里处处的是以前提交的任务，需要等待线程空闲时执行。
        * ArrayBlockingQueue：基于数组结构的有界阻塞队列，FIFO（先进先出）
        * LinkedBlockingQueue：基于链表结构的阻塞队列，FIFI（先进先出），Executors.newFixedThreadPool()【设置corePoolSize==maximumPoolSize】使用这个队列
        * SynchronousQueue: 不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作，Executors.newCachedThreadPool()使用这个队列
        * PriorityBlockingQueue: 一个具有优先级的无限阻塞队列。
    3. maximumPoolSize(线程池的最大值)   
    4. ThreadFactory：设置创建线程的工厂
    5. RejectedExecutionHandler(饱和策略)：当线程池处于饱和状态时采取的处理新提交的新任务的策略。默认AbortPolicy
        * AbortPolicy: 直接抛出异常；
        * CallerRunsPolicy: 只能调用者所在线程来运行任务；
        * DiscardOldestPolicy: 丢弃队列里最近的一个任务，并执行当前任务；
        * DiscardPolicy: 不处理，丢弃掉
    6. keepAliveTime（线程活动保持时间）：工作线程空闲后，保持存活的时间。
    7. TimeUnit(线程活动保持的单位)
3.  提交任务
    1. execute(): 没有返回值
    2. submit(): 返回Future返回值。*InterruptedException*(处理中断异常)；*ExecutionException*(处理无法执行任务异常)
4.  线程池关闭
    1. 原理：遍历线程池中的工作线程，逐个调用线程的interrupt方法来中断线程
    2. isShutdown(): 调用shutdown和shutdownnow都会变为true；
    3. isTerminaed()：所有任务已关闭后，才表示线程池关闭成功。
5.  线程池流程
    1. 判断基本线程池是否已满；
    2. 判断工作队列是否已满；
    3. 判断整个线程池是否已满；
6.  合理的配置线程池
    1. 分析任务特性
        1. 任务性质：CPU密集型任务，IO密集型任务和混合型任务。
            1. CPU密集型：尽可能小的线程（Ncpu+1），例如压缩和解压缩
            2. IO密集型：尽可能多的线程(2*Ncpu)
            3. `Runtime.getRuntime().availableProcessors()`：当前设备的CPU个数
        2. 任务优先级：高、中、低。使用*PriorityBlockingQueue*队列
        3. 任务的执行时间：长、中、短。使用不同规模的线程池来处理
        4. 任务的依赖性：是否依赖其他系统资源。设置线程数尽可能大。
    2. 建议使用*有界对列*
    3. 动态递增的增加线程池数目
7.  线程池的监控
    1. taskCount: 线程池需要执行的任务数量
    2. completedTaskCount: 线程池在运行过程中已完成的任务数量。
    3. largestTaskCount：曾经创建过的最大线程数量
    4. getPoolSize: 线程池的线程数量
    5. getActiveCount: 获取活动的线程数
    6. 重写线程池的beforeExecute、afterExecute和terminated方法。ø
8.  应急处理：如果在创建线程池的时候，指定的*corePoolSize<maximumPoolsize*是会出现你说的这种情况
## ConcurrentHashMap
1. 在并发情况下不要使用HashMap，导致CPU利用率100%；
2. HashTable容器使用synchronized来保证线程安全，但效率低下，原因是所有访问HashTable线程都必须竞争同一把锁
3. 由*Segment*数组结构和*HashEntry*数组结构组成。Segment是一把ReentrantLock锁
4. get方法，用volatile替换锁，所以读取效率比HashTable高；put方法需要用到锁
## 自旋CAS问题
1. ABA问题：如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值并没有变。*解决思路*：使用版本号。`AtomicStampedReference`来解决ABA问题
2. 循环时间长开销大
3. 只能保证一个共享变量的原子操作。
4. 使用*锁*机制实现原子操作
5. 自旋的核心。由硬件支持的一个cpu不断check高速缓存的操作，为了减少线程切换到内核态。
## ConcurrentLinkedQueue
 1. 基于链接节点的无界线程安全队列，采用先进先出的规则对节点进行排序
 2. 采用"wait-free"算法实现,默认情况下head节点存储的元素为空，tair节点等于head节点
 3. 入队列：将入队节点添加到队列的尾部
## 阻塞队列
1. 定义：一个支持两个附加操作的队列。（在队列为空时，获取元素的线程会等待队列变为非空；当队列满时，存储元素的线程会等待队列可用。）
2. 处理方法
   1. 抛出异常：当阻塞队列满时，往队列里插入元素会抛出异常；当队列为空时，从队列里获取元素时会抛出异常；
   2. 返回特殊值：插入方法会返回是否成功，成功返回TRUE；如果队列里拿出一个元素如果没有则返回null
   3. 一直阻塞：当阻塞队列满时，会阻塞往队列里put的生产者线程；当队列为空，会阻塞消费者线程，直到队列可用
   4. 超时退出：当阻塞队列满时，队列会阻塞生产者线程一段时间，如果超过一定的时间，生产者线程就会退出。
3. 7个阻塞队列
   1. ArrayBlockingQueue：一个由数组结构组成的有界阻塞队列，按照先进先出原则对元素进行排序
   2. LinkedBlockingQueue：一个由链表结构组成的有界阻塞队列，按照先进先出的原则，最大长度为`Integer.MAX_VALUE`
   3. PriorityBlockingQueue ：一个支持优先级排序的无界阻塞队列。
   4. DelayQueue：一个使用优先级队列实现的无界阻塞队列，必须实现Delayed接口，可以用于缓存系统、定时任务调度
   5. SynchronousQueue：一个不存储元素的阻塞队列，适用于将一个线程使用的数据传递给另一个线程使用
   6. LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。
   7. LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列
4. 实现原理
   1. 使用通知模式实现，当生产者往满的队列里添加元素时会阻塞住生产者，当小费者消费了一个队列中的元素后，会通知生产者当前队列可用。
   2. 利用重入锁(`ReentrantLock`)控制
## Fork/Join框架
1. 定义：用于并行执行任务的框架，是把一个大任务分割成若干个小人物，最终汇总每个小任务结果后得到大任务结果的框架
2. 两个类
   1. ForkJoinTask。(`RecursiveAction`：用于没有返回结果的任务；`RecursiveTask`：用于有返回的任务）
   2. ForkJoinPool
3. 实现原理
   1. ForkJoinPool由`ForkJoinTask`数组[负责存放程序提交给ForkJoinPool的任务]和`ForkJoinWorkerThread`数组[负责执行这些人]组成
   2. ForkJoinTask的fork原理。调用`ForkJoinWorkerThread`的`pushTask`方法，将任务存放在ForkJoinWorkerThread队列里，调用`signalWork()`异步的执行这个任务，然后立即返回结果。
   3. ForkJoinTask的join方法。阻塞当前线程并等待获取结果，四种任务状态【已完成(NORMAL)、被取消(CANCELLED)、信号(SIGNAL)和异常(EXCEPTIONAL)】
## 线程安全与共享资源
1. 局部变量中的基本数据类型(8种)永远是线程安全的
2. 局部变量中的对象类型只要不会被其他线程访问到，也是线程安全的；
3. 一个对象实例被多个线程同时访问时，他的成员变量就可能是线程不安全的；
## java内存模型[未完成]
1. 原理：划分为线程栈和堆。
   1. 线程堆。每个运行在java虚拟机里的线程都拥有自己的线程栈。包含了这个线程调用的方法当前执行点相关的信息。一个线程仅能访问自己的线程栈，一个线程创建的本地变量对其他线程不可见。每个线程拥有每个本地变量的独有版本。
   2. 堆。包含java程序创建的所有对象。不管一个对象被创建然后赋值给一个局部变量或者用来作为另一个对象的成员变量，这个对象仍然存放在堆上。
## 线程通信
1. 通过共享对象通信。
2. 忙等待。
3. wait()、notify()和notifyAll()。线程必须在同步块里调用`wait()`或`notify()`，不要使用全局对象，字符串常量等。应使用唯一的对象。
4. 丢失的信号。(**MyWaitNotify2.java**)
5. 假唤醒。线程在没有调用过`notify()`和`notifyAll()`的情况下醒来。(**MyWaitNotify3.java**)
6. 多个线程等待相同信号。(**MyWaitNotify3.java**)
7. 不要在字符串常量[**值为常量的变量**]或全局对象中调用wait()
## ThreadLocal（线程封闭）
1. 定义。创建的变量只被同一个线程进行读和写操作。`private ThreadLocal myThreadLocal  = new ThreadLocal();`，每个线程只能看到私有的ThreadLocal实例，所以不同的线程在给ThreadLocal对象设置不同的值时，他们也不能看到彼此的修改。防止对可变的单实例变量或全局变量进行共享。
2. 访问。`myThreadLocal.set("A thread local value");`或`String threadLocalValue = (String) myThreadLocal.get();`当某个频繁执行的操作需要一个临时对象，而同时又希望避免在每次执行时都重新分配该临时对象，就可以使用ThreadLocal。
3. ThreadLocal泛型。`private ThreadLocal myThreadLocal1 = new ThreadLocal<String>();`。
4. 初始化ThreadLocal。重写initialValue方法可以让所有线程都可以看到初始化值。
5. InheritableThreadLocal。为了解决ThreadLocal实例内部每个线程都只能看到自己的私有值，允许一个线程创建的所有子线程访问其父线程。
## 死锁
1. 定义。两个或更多线程阻塞着等待其它处于死锁状态的线程所持有的锁。
2. 如何发现死锁。
   1. 阅读code。检查嵌套的synchronized同步块代码或者调用synchronized方法。
   2. 利用操作系统的命令。`kill -3`。能够打印当前应用里所有线程的状态。
   3. 使用`jconsole`。
3. 解决方案。
   1. 加锁顺序。
   2. 加锁时限。在尝试获取锁的时候加一个超时时间，若一个线程没有在给定的时限内成功获得所有需要的锁，则会进行回退并释放所有已经获得的锁，然后等待一段随机的时间再重试。不能对`synchronized`同步块设置超时时间
   3. 死锁检测。
      1. 针对那些不可能实现按序加锁并且锁超时也不可行的场景。
      2. 解决方案。
         1. 释放所有锁，回退，并且等待一段随机的时间后重试。
         2. 给线程设置随机优先级。